{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5835ca9-ad2d-4acb-a804-c419c760b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession  #객체 생성\n",
    "spark= SparkSession.builder.appName(\"taxi-fare-prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1107cc09-ec80-4119-8b33-3d97726d1f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/learning_spark_data/trips/*.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd=os.getcwd()\n",
    "trip_data_path=os.path.join(cwd, 'learning_spark_data', 'trips', '*.csv') #learning_spark_data/trips 폴더 아래의 모든 .csv 파일 경로를 만듦\n",
    "trip_data_path  #여러 csv 파일 한번에 읽기 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed6f635-e2d6-478a-884b-abd49c2ad798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:////home/jovyan/work/learning_spark_data/trips/*.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=f\"file:///{trip_data_path.replace(os.sep,'/')}\"\n",
    "file_path\n",
    "\n",
    "# Spark에서 사용할 수 있는 파일 시스템 경로로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31fbc04-695e-406e-869f-f461adc4e5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_df=spark.read.csv(file_path,inferSchema=True, header=True) \n",
    "trip_df.printSchema()\n",
    "\n",
    "#inferSchema=True: 데이터 타입을 자동으로 추론\n",
    "#header=True: 첫 번째 줄을 컬럼명으로 인식\n",
    "#printSchema(): 읽어온 DataFrame의 컬럼명, 타입 구조를 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908e876-f0c0-4130-a070-1b8984a4a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#운행거리에 따른 요금 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ab18643-70c1-4cda-90ae-1ed5a5f48f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.createOrReplaceTempView('trips')\n",
    "\n",
    "#PySpark DataFrame을 'trips'라는 SQL 테이블처럼 쓸 수 있게 임시 뷰로 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3a75d6-ab13-47e6-835d-14064c037452",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "SELECT \n",
    "    trip_distance,\n",
    "    total_amount\n",
    "FROM trips\n",
    "\n",
    "WHERE total_amount<5000\n",
    "AND total_amount>0\n",
    "AND trip_distance>0\n",
    "AND trip_distance<500\n",
    "AND passenger_count<4  \n",
    "AND TO_DATE(tpep_pickup_datetime)>=\"2021-01-01\"\n",
    "AND TO_DATE(tpep_pickup_datetime)<\"2021-08-01\"\n",
    "\"\"\"\n",
    "#SQL로 데이터 전처리(필터링) 수행\n",
    "#total_amount: 0~5000 사이 (이상치, 오류값 제거)\n",
    "#trip_distance: 0~500 사이 (비정상값 제거)\n",
    "#passenger_count: 4 미만 (일반적인 소형 택시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06286b73-7070-46b4-9d72-0a1ccdba0714",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df=spark.sql(query)\n",
    "trip_df.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0034198-ec12-4c63-93ae-df8732823e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|trip_distance|total_amount|\n",
      "+-------------+------------+\n",
      "|         16.5|       70.07|\n",
      "|         1.13|       11.16|\n",
      "|         2.68|       18.59|\n",
      "|         12.4|        43.8|\n",
      "|          9.7|        32.3|\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from data limit 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6323b60a-23b5-4d8e-92f5-fb809952c5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ef7d62-ba42-4f96-88de-b5e422fd16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test split 8:2, seed=1 \n",
    "train_df,test_df=trip_df.randomSplit([0.8,0.2],seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5814133-d5e3-4514-8439-17212d5c4c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b033c745-368b-4a05-abe8-82907523c319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+\n",
      "|trip_distance|total_amount|features|\n",
      "+-------------+------------+--------+\n",
      "|         0.01|        3.05|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "|         0.01|         3.3|  [0.01]|\n",
      "+-------------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#vectorassembler>features: trip_distance,target: total_amount\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vassembler = VectorAssembler(\n",
    "    inputCols=['trip_distance'],    # 독립변수(피처) 리스트\n",
    "    outputCol='features'            # ML용 feature vector 컬럼명(관례적으로 'features')\n",
    ")\n",
    "\n",
    "vtrain_df=vassembler.transform(train_df)  #학습 데이터에서 벡터어셈블링 적용, 결과:기존 컬럼 + 'features' 컬럼 추가\n",
    "vtrain_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee4b7824-7365-497c-9f82-8105d859e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linearRegression 생성 maxIter=50, labelCol='total_amount',featureCol='features'\n",
    "#fit\n",
    "#vassembler.fransfrom(test)\n",
    "#model.transfrom\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr=LinearRegression(\n",
    "    maxIter=50,\n",
    "    featuresCol='features',   \n",
    "    labelCol='total_amount'     #목표가 labelcol ;요금\n",
    ")\n",
    "\n",
    "lr_model=lr.fit(vtrain_df) #학습 데이터로 선형회귀 모델학습\n",
    "\n",
    "vtest_df=vassembler.transform(test_df) #test데이터도 똑같이 features 벡터컬럼추가\n",
    "pred=lr_model.transform(vtest_df) #테스트셋의 각 row에 대해 예측값 컬럼이 추가된 DataFrame(pred) 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b17b4e2-b1b4-492f-b366-4420a454ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------+-----------------+\n",
      "|trip_distance|total_amount|features|       prediction|\n",
      "+-------------+------------+--------+-----------------+\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "|         0.01|         3.3|  [0.01]|9.430440745312902|\n",
      "+-------------+------------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "134b5647-c0e3-4d50-92a6-59f43e38cad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.30781413196623"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.summary.rootMeanSquaredError #RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60813cdb-148f-40e1-a09a-89be2681852d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7648633777017714"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.summary.r2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ba74c-ae0d-408c-b166-764c933f293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef3c2b2a-bb10-475e-b38a-8f9047c38488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|trip_distance|\n",
      "+-------------+\n",
      "|          1.1|\n",
      "|          5.4|\n",
      "|         10.2|\n",
      "|         30.0|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "new_distance_list=[1.1, 5.4, 10.2, 30.0]\n",
    "distance_df=spark.createDataFrame(new_distance_list,DoubleType()).toDF('trip_distance')\n",
    "distance_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f63c95a9-6a63-45bd-997b-5eaeb3b14d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+------------------+\n",
      "|trip_distance|features|        prediction|\n",
      "+-------------+--------+------------------+\n",
      "|          1.1|   [1.1]|12.672809485363317|\n",
      "|          5.4|   [5.4]|25.463805432351194|\n",
      "|         10.2|  [10.2]| 39.74212648945393|\n",
      "|         30.0|  [30.0]| 98.64020085000274|\n",
      "+-------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vdistance_df = vassembler.transform(distance_df)\n",
    "lr_model.transform(vdistance_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a32d0be3-ec8c-4b79-89cd-e9d00d9ec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
