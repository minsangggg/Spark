{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ded1b1-3037-4eda-bc1e-08116b48b1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096d3cb4-bb29-421e-8fea-f066223d1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8f69eb-f49a-4b3e-a7b1-f6521cef0c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ec8722-601b-4ab4-96e6-2359b6fa83dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk 17.0.8.1 2023-08-24\n",
      "OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab84d3a6-b2bd-4240-8056-8ea38b7f6d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/java\n"
     ]
    }
   ],
   "source": [
    "!which java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d082398-cc82-47e5-8881-30e88675ef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /usr/local/spark/python\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb2bf29-29be-4386-9b31-bd87bf84c1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SPARK_HOME\n",
    "import os\n",
    "os.environ.get('SPARK_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e41ad48-a8ad-48cf-b96e-f57ed777d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JAVA_HOME\n",
    "import os\n",
    "os.environ.get('java_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc52a2ff-0165-4ca6-aa8a-5979ccd91186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip:/usr/local/spark/python:'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('PYTHONPATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a3ffd-735b-4f86-aaf4-593c5fbb8a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a3b455-36d7-4df2-abc4-b69eac45d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining\n",
    "#SparkContext.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bab4339b-ebba-4c36-956e-b7c5bd56df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://da63fdb0ab59:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc29822e5d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c99544f-c7f5-425c-b8ea-665615a53ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "707ab13b-20d4-4739-9f17-7a1a377661c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('pyspark example1').getOrCreate() #chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea2bb370-92d9-4160-bcc2-377889d32902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://da63fdb0ab59:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc298260b10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9caec9a1-46b2-41f8-99e1-9eb419b7c545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[ ('Alice',1), ('Bob',2), ('Charlie',3) ]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed477db8-2c95-459f-960a-9fbf2c2831b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Value: bigint]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame 객체(분산객체)를 생성 <> 판다스의 데이터프레임이 아님\n",
    "data1=spark.createDataFrame(data, ['Name','Value'])\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd97a557-0182-4622-9983-1a96e9ac6b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Alice|    1|\n",
      "|    Bob|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c01f3-4d08-44b8-8939-87f8117beb71",
   "metadata": {},
   "source": [
    "## RDD 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a258c66a-122c-4248-97de-081248b99221",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('pyspark example1').getOrCreate() #기존꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3209f36a-8c15-428d-b22e-59d669e490da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[23] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd=spark.sparkContext.parallelize([1,2,3,4,5])\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "797f771b-59fa-406b-9809-b9c99b9dd5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Value: bigint]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1151355d-813d-416a-8b1e-744863591ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5) #rdd 객체를 출력하는 함수, n개 지정 필수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe34b84d-9082-4a5e-911f-3b14b0200949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[26] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map 연산:rdd 값으로 연산\n",
    "squared_rdd=rdd.map(lambda x:x*x)\n",
    "squared_rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf3642bf-9c79-4be3-bf2f-4a816f6cf64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab20fddf-a27e-4c07-b1d4-f0c1360a63bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c0ed94e-6b96-44a9-9ad7-ec712f07ecb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc5e116b-7d8c-4ed3-9da5-1d9c08e39534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "| Bob|    2|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.filter(data1.Name == 'Bob').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6a59bfa-e027-4860-ad3d-c863c5b22c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.filter(data1.Value>2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44b65c28-03b3-4692-93dc-9ab03ef32feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.createOrReplaceTempView('people')        #임시뷰로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b6bb6a2-8cb6-4d2e-942f-979de363753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Alice|    1|\n",
      "|    Bob|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from people').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec66163c-17a2-4969-bb9f-b2f7a047487e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "| Bob|    2|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from people where Name=\"Bob\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "393d40ac-4bf6-400e-b07a-3845c354ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Name,Value from people where value==3').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d24c78-5bf3-4347-a99d-852512c2223b",
   "metadata": {},
   "source": [
    "## Machine Learning library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29da652d-483a-4016-af93-f1cb6d69f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0ec3b916-8de8-4f3e-b8c2-7eebfcbbd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4737d311-d6ba-4570-8625-5beb13dfd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef5b253d-64fa-4083-9631-7ecccb619945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_age=[ ('Alice',25), ('Bob',30), ('Charlie',33) ]\n",
    "data2=spark.createDataFrame(data_age, ['Name','Age'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1672866-905b-4775-b992-67c03cace387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint, features: vector]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=['Age'],outputCol='features')\n",
    "vector_df=assembler.transform(data2)\n",
    "vector_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ae84d41-2847-48da-a4cb-b2c318269f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression(featuresCol='features',labelCol='Age')\n",
    "model=lr.fit(vector_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2fe8cc7-cc5a-41f5-815a-446cee0516ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint, features: vector, prediction: double]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.transform(vector_df)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f3ea1ff-34e2-4e7c-8553-911e3730a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+-----------------+\n",
      "|   Name|Age|features|       prediction|\n",
      "+-------+---+--------+-----------------+\n",
      "|  Alice| 25|  [25.0]|24.99999999999993|\n",
      "|    Bob| 30|  [30.0]|30.00000000000001|\n",
      "|Charlie| 33|  [33.0]|33.00000000000006|\n",
      "+-------+---+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ae8f84b-0e81-4fe5-bcef-dba511b73097",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e905d8-7bd7-40d6-9133-6bab65066fdf",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "41f42f8a-0977-4ca5-bae6-2f853a484cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "#explode(): 배열 컬럼을 행으로 분해하는 함수\n",
    "#예: ['a', 'b', 'c'] → 'a', 'b', 'c' 3개의 행으로 만들어줌\n",
    "#split(): 문자열을 지정된 구분자(예: ' ') 기준으로 잘라서 배열로 만들어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "374a46c1-b6ca-4399-b94f-693bb0065c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('pyspark example1').getOrCreate()  #SparkSession 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d8a25a0-17c8-47af-bf06-e5a265035f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.readStream.format('socket')\\\n",
    ".option('host','localhost')\\\n",
    ".option('port',9999)\\\n",
    ".load() #streaming data 받음\n",
    "\n",
    "'''스트리밍 데이터 소스를 지정함.\n",
    "이건 소켓으로부터 텍스트 데이터를 실시간으로 받는 설정이야.\n",
    "소켓에서 \"hello spark\"를 입력하면\n",
    "lines DataFrame에 value = \"hello spark\" 형태로 들어옴.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad603b6b-74d7-481a-bd0c-c72b1645539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=lines.select(explode(split(lines.value, ' ')).alias('word')\n",
    "'''\n",
    "lines.value: 소켓으로 들어온 텍스트 한 줄 (예: \"hello spark world\")\n",
    "\n",
    "split(lines.value, ' '): 공백 ' ' 기준으로 문자열을 나눠서 리스트로 만듦\n",
    "→ [\"hello\", \"spark\", \"world\"]\n",
    "\n",
    "explode(...): 리스트 안의 요소들을 각각의 행으로 분해\n",
    "→ hello, spark, world → 각각 1행씩\n",
    "\n",
    ".alias('word'): 새로 생성된 컬럼 이름을 word로 지정함\"\"\"                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c58d30c-7b7d-4e3a-b472-b5c3531b708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
