{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67742c4e-2846-4748-bdd9-c46f529bafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810f2fdf-b009-4173-8e3c-11b9fe3e3466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://b62fdf3580a1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark-sql</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9de6582350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Spark Session\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a53f7e-499f-4429-a300-4713b0480747",
   "metadata": {},
   "source": [
    "## 타이타닉 데이터를 이용한 생존여부 예측 모델\n",
    "#### 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cc9c2a-4240-4444-8029-8c6e5de26b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV 파일로드\n",
    "data=spark.read.csv(\"learning_spark_data/titanic.csv\", \n",
    "                    header=True, \n",
    "                    inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14aefd07-8f46-4e4b-81db-3a25cb580824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|Gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 확인\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcbc3241-da66-4a61-bf7e-1dc7112b8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Gender|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "|          0|       0|     0|   0|     0|177|    0|    0|     0|   0|  687|       2|\n",
      "+-----------+--------+------+----+------+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측치처리\n",
    "from pyspark.sql.functions import col,sum,when,isnan\n",
    "\n",
    "null_counts=data.select(\n",
    "   [  sum( when(col(c).isNull() | isnan(c),1).otherwise(0) ).alias(c)\n",
    "     for c in data.columns\n",
    "   ]\n",
    ")\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f417c484-989a-4fb6-8495-8f0dcca197c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+\n",
      "|Survived|Pclass|Gender| Age|Sibsp|Parch|   Fare|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|\n",
      "+--------+------+------+----+-----+-----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "data_1=data.select('Survived','Pclass','Gender','Age','Sibsp','Parch','Fare')\n",
    "data_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccf54cc-52ae-4e65-a396-453f655207eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age 결측치처리-> 평균값으로 대체\n",
    "mean_age=data_1.select('Age').agg({\"Age\":\"mean\"}).collect()[0][0] #mean은 집계함수\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e712a5fb-8b89-4ab3-abe8-b1649a00b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|Survived|Pclass|Gender|              Age|Sibsp|Parch|   Fare|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "|       0|     3|  male|             22.0|    1|    0|   7.25|\n",
      "|       1|     1|female|             38.0|    1|    0|71.2833|\n",
      "|       1|     3|female|             26.0|    0|    0|  7.925|\n",
      "|       1|     1|female|             35.0|    1|    0|   53.1|\n",
      "|       0|     3|  male|             35.0|    0|    0|   8.05|\n",
      "|       0|     3|  male|29.69911764705882|    0|    0| 8.4583|\n",
      "|       0|     1|  male|             54.0|    0|    0|51.8625|\n",
      "|       0|     3|  male|              2.0|    3|    1| 21.075|\n",
      "|       1|     3|female|             27.0|    0|    2|11.1333|\n",
      "|       1|     2|female|             14.0|    1|    0|30.0708|\n",
      "+--------+------+------+-----------------+-----+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1=data_1.fillna({'Age':mean_age})\n",
    "data_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed4d3f66-89b6-4e42-9545-2c841995d71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|Survived|Pclass|Gender| Age|Sibsp|Parch|   Fare|SexIndexer|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       0.0|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       1.0|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       1.0|\n",
      "+--------+------+------+----+-----+-----+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 인코딩 StringIndexer\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "indexer=StringIndexer(inputCol='Gender',outputCol='SexIndexer')\n",
    "data_1=indexer.fit(data_1).transform(data_1)\n",
    "data_1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ce9bdd-d743-4e8b-a443-eec4f015e130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Survived|\n",
      "+--------------------+--------+\n",
      "|[3.0,0.0,22.0,1.0...|       0|\n",
      "|[1.0,1.0,38.0,1.0...|       1|\n",
      "|[3.0,1.0,26.0,0.0...|       1|\n",
      "|[1.0,1.0,35.0,1.0...|       1|\n",
      "|[3.0,0.0,35.0,0.0...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FeatureVector 생성\n",
    "assembler=VectorAssembler(\n",
    "    inputCols=['Pclass','SexIndexer','Age','Sibsp','Parch','Fare'],\n",
    "    outputCol='features'\n",
    "\n",
    ")\n",
    "data_1=assembler.transform(data_1)\n",
    "data_1.select('features','Survived').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48b58da1-e9d7-4909-9b0b-5c594fbdd0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|Survived|Pclass|Gender| Age|Sibsp|Parch|  Fare|SexIndexer|            features|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "|       0|     1|female| 2.0|    1|    2|151.55|       1.0|[1.0,1.0,2.0,1.0,...|\n",
      "|       0|     1|female|25.0|    1|    2|151.55|       1.0|[1.0,1.0,25.0,1.0...|\n",
      "|       0|     1|  male|18.0|    1|    0| 108.9|       0.0|[1.0,0.0,18.0,1.0...|\n",
      "|       0|     1|  male|19.0|    1|    0|  53.1|       0.0|[1.0,0.0,19.0,1.0...|\n",
      "|       0|     1|  male|19.0|    3|    2| 263.0|       0.0|[1.0,0.0,19.0,3.0...|\n",
      "+--------+------+------+----+-----+-----+------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|Survived|Pclass|Gender|              Age|Sibsp|Parch|   Fare|SexIndexer|            features|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "|       0|     1|female|             50.0|    0|    0|28.7125|       1.0|[1.0,1.0,50.0,0.0...|\n",
      "|       0|     1|  male|             21.0|    0|    1|77.2875|       0.0|[1.0,0.0,21.0,0.0...|\n",
      "|       0|     1|  male|             24.0|    0|    0|   79.2|       0.0|[1.0,0.0,24.0,0.0...|\n",
      "|       0|     1|  male|             29.0|    0|    0|   30.0|       0.0|[1.0,0.0,29.0,0.0...|\n",
      "|       0|     1|  male|29.69911764705882|    0|    0|  26.55|       0.0|[1.0,0.0,29.69911...|\n",
      "+--------+------+------+-----------------+-----+-----+-------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 분할\n",
    "train_data,test_data=data_1.randomSplit([0.8,0.2],seed=42)\n",
    "train_data.show(5), test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd5353e4-0f05-45e1-a1ba-82d9edbe68bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----------+\n",
      "|            features|Survived|prediction|\n",
      "+--------------------+--------+----------+\n",
      "|[1.0,1.0,50.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,21.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,24.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.0,0.0...|       0|       1.0|\n",
      "|[1.0,0.0,29.69911...|       0|       1.0|\n",
      "+--------------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr=LogisticRegression(featuresCol='features', labelCol='Survived')\n",
    "lr_model=lr.fit(train_data)\n",
    "predic=lr_model.transform(test_data)\n",
    "predic.select('features','Survived','prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e45186-a66d-4dbe-9378-16428cbf57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+\n",
      "|Survived|prediction|count|\n",
      "+--------+----------+-----+\n",
      "|       1|       0.0|   16|\n",
      "|       0|       0.0|   72|\n",
      "|       1|       1.0|   45|\n",
      "|       0|       1.0|   12|\n",
      "+--------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic.select('Survived','prediction').groupBy('Survived','prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0546bef6-55ad-4cf9-a0a7-d12b3b1b56c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "comp=predic.withColumn('correct', expr('case when Survived=prediction then 1 else 0 end'))\n",
    "comp.where('correct=0').count()     #1인데 0으로 나온것과 0인데 1로 나온거 확인. 즉, 틀린것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
